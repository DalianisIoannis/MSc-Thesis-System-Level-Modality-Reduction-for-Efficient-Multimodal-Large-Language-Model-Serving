# MSc-Thesis-System-Level-Modality-Reduction-for-Efficient-Multimodal-Large-Language-Model-Serving

## Abstract
Deploying large Multimodal Large Language Models (MLLMs) in production is critically bottlenecked by their immense computational and memory demands, stemming from the Transformer's quadratic complexity in the prefill phase and the resulting Key-Value (KV) cache memory exhaustion. This thesis addresses these system challenges by validating modality reduction as a powerful, system-level optimization technique. We perform a rigorous performance analysis using a diverse MLLM set served by the high-throughput engine vLLM on NVIDIA A100 hardware, evaluating the trade-off between speed and task quality across image and video workloads. Our findings quantify the effectiveness of two primary reduction strategies. For image workloads, proportional image downsizing achieves up to a 51% reduction in Time-to-First-Token (TTFT) and a 53% reduction in KV cache memory footprint with minimal degradation in quality (~-4% Accuracy loss). For video workloads, Scene Change detection for intelligent frame sampling delivers even more substantial gains, achieving up to a 79% reduction in TTFT and a 76% reduction in memory overhead, while retaining competitive task quality. These results establish modality reduction as an essential system-level technique for maximizing the serving capacity and minimizing the latency of MLLMs, providing the foundational data necessary for building next-generation dynamic inference serving systems.

***Implementation will soon be available***
